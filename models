import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.neural_network import MLPRegressor
from sklearn.svm import SVR
from xgboost import XGBRegressor
import matplotlib.pyplot as plt
import seaborn as sns

data = pd.read_csv('path_to_your_data.csv')
X = data.drop('target_column', axis=1)
y = data['target_column']


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)


models = {
    "RandomForest": RandomForestRegressor(),
    "GradientBoosting": GradientBoostingRegressor(),
    "XGBoost": XGBRegressor(),
    "MLPRegressor": MLPRegressor(),
    "SVR": SVR()
}

# Hyperparameters for each model
param_grid = {
    "RandomForest": {'n_estimators': [100, 200], 'max_depth': [10, 20]},
    "GradientBoosting": {'learning_rate': [0.01, 0.1], 'n_estimators': [100, 200]},
    "XGBoost": {'learning_rate': [0.01, 0.1], 'n_estimators': [100, 200], 'max_depth': [5, 10]},
    "MLPRegressor": {'hidden_layer_sizes': [(50,50,50), (50,100,50)], 'activation': ['tanh', 'relu']},
    "SVR": {'kernel': ['linear', 'rbf'], 'C': [1, 10]}
}


results = []
for model_name, model in models.items():
    grid_search = GridSearchCV(model, param_grid[model_name], cv=5, scoring='neg_mean_squared_error')
    grid_search.fit(X_train, y_train)
    best_model = grid_search.best_estimator_
    predictions = best_model.predict(X_test)

  
    mse = mean_squared_error(y_test, predictions)
    r2 = r2_score(y_test, predictions)
    results.append((model_name, mse, r2))

# Plotting results
results_df = pd.DataFrame(results, columns=['Model', 'MSE', 'R2'])
sns.barplot(x='Model', y='MSE', data=results_df)
plt.title('Model Comparison - Mean Squared Error')
plt.show()

sns.barplot(x='Model', y='R2', data=results_df)
plt.title('Model Comparison - R2 Score')
plt.show()
